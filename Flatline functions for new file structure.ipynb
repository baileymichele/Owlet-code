{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import sqlalchemy as sql\n",
    "from tqdm import tqdm_notebook\n",
    "from datetime import date, datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatline Algorithm Using Data on Big Mama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '16k_round_3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load list of dsns in this round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dsns = pickle.load(open(f'{folder}/rollups_dsns.p','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle inclusion dsns (the only thing not taken into account yet will be those with no data)\n",
    "\n",
    "    *Remember that we are only doing babies w/ bdays in a certain range and that are the first to use the device*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsns_with_info = pickle.load(open('all_dsns_with_info.p','rb')) # includes cc dsns\n",
    "baby_info = pickle.load(open('16k_reg_and_cc_bdays4.p','rb'))\n",
    "v2_devices = pickle.load(open('/Users/brodriguez/Documents/Owlet-code/V2_monitoring_data/v2_devices.p', 'rb'))\n",
    "inclusion_dsns = set(list_of_dsns).intersection(dsns_with_info).intersection(v2_devices).intersection(baby_info.dsn.values)\n",
    "\n",
    "more_than_5_bdays = set(pickle.load(open('dsns_more_than_5_bdays.p', 'rb'))).intersection(inclusion_dsns)\n",
    "for dsn in more_than_5_bdays:\n",
    "    inclusion_dsns.remove(dsn)\n",
    "    \n",
    "pickle.dump(inclusion_dsns, open(f'/Users/brodriguez/Documents/Owlet-code/{folder}/inclusion_dsns.p', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get locations for inclusion dsns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_data = pd.read_csv('/Users/brodriguez/Documents/Owlet-code/GPS_locations_Mar_2019.csv', compression='gzip')\n",
    "def dsn_in_16000(x):\n",
    "    if x['dsn'] in inclusion_dsns:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Location info for only the 16000 dsns (otherwise the df is too big and it slows everything down)\n",
    "in_16000 = location_data.apply(dsn_in_16000, axis=1)\n",
    "location_data = location_data.loc[in_16000].sort_values(by='created_at')\n",
    "\n",
    "pickle.dump(location_data, open(f'/Users/brodriguez/Documents/Owlet-code/{folder}/16000_location_data.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find critical events (load 10 min rollups with query on big mama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary(x):\n",
    "    '''Convert int to binary and return indices of bits that are 1\n",
    "    \n",
    "    Args:\n",
    "      x (int): bit mask\n",
    "      \n",
    "    Returns:\n",
    "      list: indices where bit mask is true\n",
    "    '''\n",
    "    bi = list(bin(x)[2:])[::-1]\n",
    "    indices = np.where(np.array(bi) == \"1\")[0]\n",
    "    return indices\n",
    "\n",
    "def at_risk(df):\n",
    "    '''Indicate whether there was 24 hours of base state 7 data\n",
    "    \n",
    "    Args:\n",
    "      df (Dataframe): all 10 minute rollup data for a given device\n",
    "      \n",
    "    Returns:\n",
    "      boolean: False if there was at least 24 hours of data at base state 7\n",
    "    '''\n",
    "    if df.shape[0] < 144: \n",
    "        # Less than 24 hours of use\n",
    "        return True\n",
    "    else:\n",
    "        count = 0\n",
    "        for row in df.itertuples():\n",
    "            if 7 in binary(int(row.BaseStateMask)):\n",
    "                count += 1\n",
    "            if count >= 144:\n",
    "                return False\n",
    "    if count >= 144:\n",
    "        return False\n",
    "    else:\n",
    "        # Less than 24 hours of base state 7 (successful monitoring)\n",
    "        return True\n",
    "    \n",
    "def find_last_day(dsn, df_all, dsn_bdays, dsns_1_bday):\n",
    "    '''Find the last day that the first baby used the device\n",
    "    \n",
    "    Args:\n",
    "      dsn (str)            : device number\n",
    "      df_all (Dataframe)   : 10 minute rollup data for the given device\n",
    "      dsn_bdays (Dataframe): reported birthdays for all devices\n",
    "      dsns_1_bday (list)   : list of dsns that have 1 reported birthday\n",
    "      \n",
    "    Returns:\n",
    "      Timestamp : Last day that there was data for the dsn\n",
    "    '''\n",
    "    # if there is only 1 unique bday: return  very last day of use\n",
    "    dsn_bdays = list(dsn_bdays.sort_values(by='created_at').created_at)\n",
    "    if (dsn in dsns_1_bday) or (len(dsn_bdays) == 1):\n",
    "        return list(df_all.TimeWindowStartTime)[-1]\n",
    "    else:\n",
    "        #  take last use before second birthday was reported\n",
    "        df_all = df_all.loc[(df_all.TimeWindowStartTime >=  dsn_bdays[0]) & (df_all.TimeWindowStartTime <  dsn_bdays[1])]\n",
    "        if df_all.shape[0] == 0:\n",
    "            # No data between 1st 2 reported bdays\n",
    "            return -1\n",
    "        return list(df_all.TimeWindowStartTime)[-1]\n",
    "    \n",
    "\n",
    "def baby_age(day, baby_df, no_reg):\n",
    "    '''Get the age and birthday of a baby\n",
    "    \n",
    "    Args:\n",
    "      day (Timestamp)    : The last day the device was used\n",
    "      baby_df (Dataframe): birthday information for a specific device\n",
    "      no_reg (boolean)   : True if there is no record of registration for the device\n",
    "      \n",
    "    Returns:\n",
    "      Timedelta : age of the baby in days\n",
    "      str       : Baby's birthday\n",
    "    '''\n",
    "    # Still would need to modify the birthday data to have a column with the reported date\n",
    "    if no_reg:\n",
    "        return pd.Timedelta(days=1), ''\n",
    "    relevant_birthdays = baby_df.loc[baby_df.created_at <= str(day)] # What was reported before the last use\n",
    "    if relevant_birthdays.shape[0] == 0:\n",
    "        return pd.Timedelta(days=-1), ''\n",
    "    else:\n",
    "        # Use the last reported bday\n",
    "        last_reported = max(relevant_birthdays.created_at.values)\n",
    "        bday = relevant_birthdays.query('created_at == @last_reported').birthDate.values[0]\n",
    "    \n",
    "    age = day.date() - date(int(bday[:4]), int(bday[4:6]), int(bday[6:]))# diff between birthday and day of incident\n",
    "    \n",
    "    return age, bday \n",
    "\n",
    "def in_US(day, location_df, no_reg):\n",
    "    '''Find out if device was used in the US\n",
    "    \n",
    "    Args:\n",
    "      day (Timestamp)        : The last day the device was used\n",
    "      location_df (Dataframe): location information for a specific device\n",
    "      no_reg (boolean)       : True if there is no record of registration for the device\n",
    "      \n",
    "    Returns:\n",
    "      boolean : True if the device was used in the US before last day of use\n",
    "    '''\n",
    "    \n",
    "    if no_reg:\n",
    "        return True\n",
    "    location = location_df.loc[location_df.created_at <= str(day)]\n",
    "    if location.shape[0] == 0:\n",
    "        # Don't know the location\n",
    "        return False\n",
    "    elif location.cc.iloc[-1] != 'US':\n",
    "        return False\n",
    "    else:\n",
    "        return True \n",
    "\n",
    "def get_df_day(df_all, day):\n",
    "    '''Get 2 hours of data just prior to the time given\n",
    "    \n",
    "    Args:\n",
    "      df_all (Dataframe): 10 minute rollup data for a specific device\n",
    "      day (Timestamp)   : The last day the device was used\n",
    "      \n",
    "    Returns:\n",
    "      boolean : True if the device was used in the US before last day of use\n",
    "    '''\n",
    "    # return the 2 hours just prior to the datetime (and include the datetime)\n",
    "    # if there is not data in the 2 hours before, it will get what is there\n",
    "    prior_2_hrs = day - pd.Timedelta(120,'m')\n",
    "    return df_all[(df_all.TimeWindowStartTime >= prior_2_hrs) & (df_all.TimeWindowStartTime <= day)] #.TimeWindowStartTime or .FirstReadingTime\n",
    "\n",
    "\n",
    "def possible_flatline(df, low_HR_thres, high_HR_thres, low_O2_thres, valid_thres):\n",
    "    '''Find critical events (high or low heart rate or low oxygen) in the data given\n",
    "    \n",
    "    Args:\n",
    "      df (Dataframe)     : 2 second data for a last day of use\n",
    "      low_HR_thres (int) : threshold for low heart rate\n",
    "      high_HR_thres (int): threshold for high heart rate\n",
    "      low_O2_thres (int) : threshold for low oxygen \n",
    "      valid_thres (float): threshold for valid data\n",
    "      \n",
    "    Returns:\n",
    "      str : 'True' or 'True + description' if vitals were outside of thresholds, else 'False'\n",
    "    '''\n",
    "    valid_percent = df.ValidSamples/df.TotalSamples\n",
    "    \n",
    "    # We don't alert for low HR unless O2 is also low.\n",
    "    critical_vitals = ((df.HeartRateRawMin < low_HR_thres) & (df.OxygenRawMin < 90)) | (df.OxygenRawMin < low_O2_thres) | (df.HeartRateRawMax > high_HR_thres)\n",
    "    critical_event = any(critical_vitals & (valid_percent >= valid_thres))\n",
    "    \n",
    "    if critical_event:\n",
    "        # Low HR won't be valid if the O2 is not actually dropping\n",
    "        if all(df.HeartRateRawMax < 220) & all(df.OxygenAvgMin >= 90):\n",
    "            # Check how many times oxygen_raw_min was below 60 \n",
    "            if (df.OxygenRawMin < 60).sum() >= 5:\n",
    "                # For cases of Oxygen Noise Index (indicating bad hardware)\n",
    "                return 'True, many instantaneous'\n",
    "            return 'True, instantaneous'\n",
    "        elif all(df.HeartRateRawMax < 220) & all(df.OxygenAvgMin < 90): \n",
    "            # this category is just a \"nice to know\"\n",
    "            return 'True, low baseline'\n",
    "        else:\n",
    "            return 'True'\n",
    "    else:\n",
    "        return 'False'\n",
    "    \n",
    "\n",
    "def last_vitals(df):\n",
    "    '''Description of last vitals during last 10 minutes\n",
    "    \n",
    "    Args:\n",
    "      df (Dataframe): data for a devices last 2 hours of use\n",
    "      \n",
    "    Returns:\n",
    "      str : description of vitals in last 10 minutes\n",
    "    '''\n",
    "    if df.shape[0] == 0:\n",
    "        return 'not valid'\n",
    "    else:\n",
    "        last_30_min = df.loc[df.ValidSamples > 0].iloc[-3:] # last 30 min or less\n",
    "        end_min_hr = last_30_min.HeartRateAvgMin.min() \n",
    "        end_max_hr = last_30_min[-2:].HeartRateAvgMax.max()# dont want 30 min\n",
    "        end_avg_o2 = last_30_min.OxygenAvgMin.min()\n",
    "        end_raw_o2 = last_30_min.OxygenRawMin.min()       \n",
    "    if (end_min_hr < 60) & (end_avg_o2 < 80): # TODO O2 threshold here may be too low\n",
    "        return 'low HR'\n",
    "    elif (end_max_hr > 220):\n",
    "        return 'high HR'\n",
    "    # if o2 < 70 make extra low o2 category?\n",
    "    elif (end_raw_o2 < 80) & (end_avg_o2 < 85): # Avg min? < 90?\n",
    "        return 'low O2'\n",
    "    else:\n",
    "        return 'Good vitals'\n",
    "    \n",
    "\n",
    "def find_critical_events(dsn_list, location_data, baby_info, dsns_1_bday, conn, low_HR_thres=60, high_HR_thres=220, O2_thres=70, valid_thres=.4, no_reg=False):\n",
    "    '''Find all last use cases and classify critical events\n",
    "    \n",
    "    Args:\n",
    "      dsn_list (list)          : all dsns to analyze\n",
    "      location_data (Dataframe): location information for all devices\n",
    "      baby_info (Dataframe)    : birthday information for all devices\n",
    "      dsns_1_bday (list)       : list of dsns that have 1 reported birthday\n",
    "      conn (Connection)        : connection to big mama\n",
    "      low_HR_thres (int)       : threshold for low heart rate\n",
    "      high_HR_thres (int)      : threshold for high heart rate\n",
    "      low_O2_thres (int)       : threshold for low oxygen \n",
    "      valid_thres (float)      : threshold for valid data\n",
    "      no_reg (boolean)         : True if there is no record of registration for the device\n",
    "      \n",
    "    Returns:\n",
    "      Dataframe : columns describing last use of all inclusion devices\n",
    "    '''\n",
    "    count_total = 0\n",
    "    count = 0\n",
    "    classifications = []\n",
    "    cc_dsns = pickle.load(open('cc_dsns.p', 'rb')) # dsns with connected care\n",
    "    for dsn in tqdm_notebook(dsn_list):\n",
    "        # sorted/duplicate timestamps have been dropped (rollup algorithm)\n",
    "\n",
    "        df_all = pd.read_sql('select * from tenminsock where dsn = %(d)s', conn, params={'d':dsn})\n",
    "        # Won't take as long if I don't need to load all of the data to df_all\n",
    "        df_all = df_all.drop_duplicates()\n",
    "        df_all = df_all.sort_values(by='TimeWindowStartTime')\n",
    "        \n",
    "        at_risk_or_hardware = at_risk(df_all)\n",
    "        valid_df = df_all.loc[df_all.ValidSamples > 2] # > 2 so we don't miss possible cases, but also dont base critical event on 1 reading\n",
    "        dsn_location = location_data.loc[location_data.dsn == dsn] \n",
    "        dsn_baby_info = baby_info.loc[baby_info.dsn == dsn] \n",
    "\n",
    "        # df could be empty! if so, skip it\n",
    "        if valid_df.shape[0] != 0:\n",
    "            last_day = find_last_day(dsn, valid_df, baby_info.loc[baby_info.dsn == dsn],dsns_1_bday)\n",
    "            if last_day != -1:\n",
    "                # there is data for 1st baby\n",
    "                if dsn in cc_dsns:\n",
    "                    cc = 1\n",
    "                else:\n",
    "                    cc = 0\n",
    "                # Calculate age of baby and dont check for critical events if they are older than 1\n",
    "                age, bday = baby_age(last_day, dsn_baby_info, no_reg)\n",
    "                # CHECK FOR BIRTHDAY IN THE EXPECTED RANGE (Feb-oct 2017)\n",
    "                if bday > '20170222' and bday <= '20171017':\n",
    "                    count_total += 1\n",
    "                    if (age < pd.Timedelta(days=365)) and (age >= pd.Timedelta(days=0)):\n",
    "                        count += 1\n",
    "                        # if day is w/in 2 weeks of last day we have data (shouldnt happen unless we need to do bdays after oct)\n",
    "        #                 if (str(day) <= two_weeks_before_received) & (str(day) >= '2017-01-31 23:59:59'):\n",
    "\n",
    "                        # Check if in the US\n",
    "                        if in_US(last_day, dsn_location, no_reg):\n",
    "                            df_day = get_df_day(valid_df, last_day)\n",
    "                            flatline = possible_flatline(df_day, low_HR_thres, high_HR_thres, O2_thres, valid_thres)\n",
    "                            vitals = last_vitals(df_day) \n",
    "                            classifications.append((dsn, last_day.date(), flatline, vitals, cc, at_risk_or_hardware, age, bday))\n",
    "\n",
    "                    elif age >= pd.Timedelta(days=365):\n",
    "                        # add row for older babies so we know the actual last day of use\n",
    "                        classifications.append((dsn, last_day.date(), 'False', 'Good vitals', cc, at_risk_or_hardware, age, bday))\n",
    "\n",
    "    print('total babies with last day', count_total)\n",
    "    print('total babies < 1 on last day', count)\n",
    "    df_columns = ['dsn', 'date', 'critical_event', 'last_10_minutes', 'cc', 'at_risk_or_issues', 'baby_age', 'birthday']\n",
    "    df_classified = pd.DataFrame(classifications, columns=df_columns)\n",
    "    \n",
    "    return df_classified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sock off classifications..How to access 2 second data? Same way as SVT?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_2sec(dsn, day, time_index=False):\n",
    "    '''Load 2 second data for the given dsn and day\n",
    "    \n",
    "    Args:\n",
    "      dsn (str)           : device number\n",
    "      day (Date)          : last day of use\n",
    "      time_index (boolean): make timestamp the index or not\n",
    "      \n",
    "    Returns:\n",
    "      Dataframe : 2 second data for the given dsn and day\n",
    "    '''\n",
    "    if folder == '16k_round_1':\n",
    "        df_2sec = pd.read_csv(f'/Users/brodriguez/Documents/Owlet-code/{folder}/16000_2sec/{day}/{dsn}.csv.zip',names=column_names)\n",
    "    else:\n",
    "        df_2sec = pd.read_csv(f'/Users/brodriguez/Documents/Owlet-code/{folder}/16000_2sec/{day}/{dsn}.csv.gz',compression='gzip',names=column_names)\n",
    "    df_2sec.timestamp = pd.to_datetime(df_2sec.timestamp, unit='s')\n",
    "    df_2sec = df_2sec.sort_values(by=['timestamp'])\n",
    "    df_2sec.drop_duplicates('timestamp',inplace=True)\n",
    "\n",
    "    df_2sec = df_2sec.loc[(df_2sec.ble_rssi != 0)]\n",
    "    df_2sec.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    if time_index:\n",
    "        df_2sec.set_index('timestamp',inplace=True)\n",
    "    \n",
    "    return df_2sec\n",
    "\n",
    "def lost_signal(df):\n",
    "    '''Find the timestamp when the signal is lost\n",
    "    \n",
    "    Args:\n",
    "      df (Dataframe): non charging data\n",
    "      \n",
    "    Returns:\n",
    "      int : index when the signal was lost\n",
    "    '''\n",
    "    consecutive_valid = df.notification_mask.eq(0).rolling(window=16).sum().fillna(0)\n",
    "    if consecutive_valid[consecutive_valid>=15].shape[0] == 0:\n",
    "        return 0\n",
    "    return consecutive_valid[consecutive_valid>=15].index[-1]\n",
    "\n",
    "def multiple_sock_off(df, thresh=-.05):\n",
    "    '''Find the timestamps when the sock is taken off\n",
    "    \n",
    "    Args:\n",
    "      df (Dataframe): non charging data\n",
    "      \n",
    "    Returns:\n",
    "      list : list of indices when the sock came off\n",
    "   '''\n",
    "    diff_new = df.skin_temperature.diff().fillna(0)\n",
    "    diff_rolling = diff_new.rolling(300).mean().fillna(method='bfill') # different window?\n",
    "    off_indices = []\n",
    "    # find ALL indices of min..\n",
    "    if min(diff_rolling) < thresh: # < must match one for less_than\n",
    "        less_than = diff_rolling[diff_rolling < thresh]\n",
    "        \n",
    "        # 0 accounts for first time it is below threshold, > 30 accounts for multiple sock offs\n",
    "        drop_indices = [0] + list(np.where(np.diff(less_than.index.values) > 30)[0] + 1)\n",
    "        drop_indices = less_than.index.values[drop_indices]\n",
    "        \n",
    "        # For each index:\n",
    "        for i in drop_indices:\n",
    "            if i == 0:\n",
    "                off_indices.append(0)\n",
    "            else:\n",
    "                off = diff_new.iloc[max(0,(i-275)):i]\n",
    "                off = off.loc[off != 0]\n",
    "                \n",
    "                if off.shape[0] == 0:\n",
    "                    off_indices.append(i)#??????\n",
    "                else:\n",
    "                    # - 3 because window = 4, max(0, ) because if idxmax < 3 you get a negative index\n",
    "                    off_index_reset = max(0, off.eq(-1).reset_index().skin_temperature.rolling(window=4).sum().fillna(0).idxmax() - 3)\n",
    "                    count_neg_1 = off.iloc[off_index_reset:].eq(-1).value_counts()\n",
    "\n",
    "                    #  if there are no False or no True:\n",
    "                    if len(count_neg_1) == 1:\n",
    "                        if count_neg_1.index[0]:\n",
    "                            off_index = off.index[off_index_reset]\n",
    "                            off_indices.append(off_index)\n",
    "                    elif count_neg_1[True]/(count_neg_1[False] + count_neg_1[True]) >= .7: # What threshhold?\n",
    "                        off_index = off.index[off_index_reset] # This is the index where the sock came off\n",
    "                        off_indices.append(off_index)\n",
    "                    \n",
    "    return off_indices\n",
    "\n",
    "def mvmt(x):\n",
    "    '''\n",
    "    Args:\n",
    "      x (int): notifications bit mask\n",
    "      \n",
    "    Returns:\n",
    "      int : 1 if there was movement, else 0\n",
    "   '''\n",
    "    if x == 0:\n",
    "        return 1\n",
    "    return int(bin(x)[-2])\n",
    "\n",
    "def signal_sock(x):\n",
    "    '''Determine if the sock came off before the signal was lost\n",
    "    \n",
    "    Args:\n",
    "      x (Series): Row of a dataframe\n",
    "      \n",
    "    Returns:\n",
    "      str : Information on whether sock came off\n",
    "   '''\n",
    "    five_min = pd.Timedelta(minutes=5) #  is 5 min right choice\n",
    "    try:\n",
    "        df = load_2sec(x['dsn'], str(x['date']).replace('-','')) \n",
    "    except FileNotFoundError:\n",
    "        return 'Need data'\n",
    "    \n",
    "    df_non_charging = df.loc[(df.base_state > 3) & (df.heart_rate_raw != 0)]\n",
    "    df_non_charging.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    broken_sensor = any((df_non_charging.skin_temperature < 120) & (df_non_charging.skin_temperature > 0))\n",
    "    \n",
    "    time_values = df_non_charging.timestamp\n",
    "    last_reading = df_non_charging.timestamp.values[-1]\n",
    "    \n",
    "    loss = lost_signal(df_non_charging)\n",
    "    sock = multiple_sock_off(df_non_charging)\n",
    "    \n",
    "    # does the sock come off within 15 minutes of signal loss?\n",
    "    last_base_state = df.loc[df.timestamp <= time_values[loss] + pd.Timedelta(15,'m')].iloc[-1].base_state \n",
    "#     print('last base state',last_base_state, 'signal loss', time_values[loss])\n",
    "    # make timestamp the index\n",
    "    df_non_charging.set_index('timestamp',inplace=True)\n",
    "    mvmt_flag = df_non_charging.loc[(df_non_charging.index > time_values[loss]) & (df_non_charging.index < last_reading)].notification_mask.apply(mvmt) # are thresholds good?\n",
    "    \n",
    "    # if lost signal is within 1 min of last reading (before charging) return 'data cut off' \n",
    "    if abs(time_values[loss] - last_reading) < pd.Timedelta(minutes=1): # is 1 min good?\n",
    "        if last_base_state == 3:\n",
    "            return 'sock off'\n",
    "        else:\n",
    "            return 'data cut off'\n",
    "        \n",
    "    elif broken_sensor == True:\n",
    "        if last_base_state == 3:\n",
    "            return 'sock off'\n",
    "        else:\n",
    "            return 'unknown'\n",
    "    \n",
    "    # if sock comes off w/in ~5 min of lost signal return 'sock off'\n",
    "    # sock off has to be at the end not beginning***\n",
    "    elif len(sock) > 0: \n",
    "        for sock_off in sock:\n",
    "            # if sock off is way before loss no sock off...\n",
    "            if abs(sock_off - loss) > 1800: # Don't care about sock off more than 30 minutes before the signal was lost\n",
    "                # if the sock came off before going on again\n",
    "                pass\n",
    "            elif (sock_off < loss) or (abs(time_values[sock_off] - time_values[loss]) <= five_min): # is 5 minutes good?\n",
    "                return 'sock off' \n",
    "            else:\n",
    "                # if time btw loss and sock off has movement > 20% of the time => cut off \n",
    "                loss_to_off = mvmt_flag.loc[mvmt_flag.index < (time_values[sock_off] - pd.Timedelta(minutes=5))].rolling(window=100).sum().fillna(method='bfill')\n",
    "                if loss_to_off.min() < 15: # 20% or more?\n",
    "                    return 'signal lost before sock off'\n",
    "                else:\n",
    "                    return 'sock off' # sock off or data cut off?\n",
    "    \n",
    "    elif dead_battery(df_non_charging):\n",
    "        # Check for dead battery after checking for sock off (if battery dies after sock off we don't care)\n",
    "        return 'battery died'\n",
    "    \n",
    "    # if time btw loss and last reading has movement > 20% => cut off\n",
    "    loss_to_last = mvmt_flag.rolling(window=100).sum().fillna(method='bfill')\n",
    "    if loss_to_last.min() > 15: # 20% or more?\n",
    "        if last_base_state == 3:\n",
    "            return 'sock off'\n",
    "        else:\n",
    "            return 'data cut off'\n",
    "    \n",
    "    if last_base_state == 3:\n",
    "        return 'sock off'\n",
    "    return 'signal lost before sock off'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "letmein\n"
     ]
    }
   ],
   "source": [
    "DB_USER = 'brodriguez'\n",
    "DB_PASSWORD = input()\n",
    "DB_CONN = 'localhost'\n",
    "DB_NAME = 'owletsock'\n",
    "# SQL login\n",
    "s = f'mysql+pymysql://{DB_USER}:{DB_PASSWORD}@{DB_CONN}/{DB_NAME}'\n",
    "engine = sql.create_engine(s)\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '16k_round_2'\n",
    "inclusion_dsns = pickle.load(open(f'/Users/brodriguez/Documents/Owlet-code/{folder}/inclusion_dsns.p', 'rb'))\n",
    "location_data = pickle.load(open(f'/Users/brodriguez/Documents/Owlet-code/{folder}/16000_location_data.p', 'rb'))\n",
    "dsns_1_bday = pickle.load(open('dsns_1_bday.p', 'rb'))\n",
    "baby_info = pickle.load(open('16k_reg_and_cc_bdays4.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inclusion_dsns = inclusion_dsns.intersection(baby_info.dsn.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2335ea1c70448c5b0e2bdde4298963a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "total babies with last day 1\n",
      "total babies < 1 on last day 1\n"
     ]
    }
   ],
   "source": [
    "df_classified = find_critical_events(list(inclusion_dsns)[:1], location_data, baby_info, dsns_1_bday, conn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(df_classified, open('round_2_classified_test.p','wb'))\n",
    "# df_classified = pickle.load(open('round_2_classified_test.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dsn</th>\n",
       "      <th>date</th>\n",
       "      <th>critical_event</th>\n",
       "      <th>last_10_minutes</th>\n",
       "      <th>cc</th>\n",
       "      <th>at_risk_or_issues</th>\n",
       "      <th>baby_age</th>\n",
       "      <th>birthday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>AC000W001060959</td>\n",
       "      <td>2018-02-12</td>\n",
       "      <td>True, low baseline</td>\n",
       "      <td>low O2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>251 days</td>\n",
       "      <td>20170606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>AC000W001087323</td>\n",
       "      <td>2017-03-13</td>\n",
       "      <td>True, low baseline</td>\n",
       "      <td>low O2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>21 days</td>\n",
       "      <td>20170220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>AC000W001041852</td>\n",
       "      <td>2018-02-26</td>\n",
       "      <td>True, low baseline</td>\n",
       "      <td>low O2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>324 days</td>\n",
       "      <td>20170408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>AC000W001205802</td>\n",
       "      <td>2018-11-05</td>\n",
       "      <td>True</td>\n",
       "      <td>low O2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>165 days</td>\n",
       "      <td>20180524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>AC000W001066401</td>\n",
       "      <td>2018-07-11</td>\n",
       "      <td>True</td>\n",
       "      <td>low O2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>186 days</td>\n",
       "      <td>20180106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>AC000W001052267</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>True</td>\n",
       "      <td>low O2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>9 days</td>\n",
       "      <td>20171011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>AC000W000505417</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>True, low baseline</td>\n",
       "      <td>low O2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>2 days</td>\n",
       "      <td>20170429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>AC000W001067140</td>\n",
       "      <td>2017-11-09</td>\n",
       "      <td>True</td>\n",
       "      <td>low O2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>10 days</td>\n",
       "      <td>20171030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>AC000W002575870</td>\n",
       "      <td>2018-08-16</td>\n",
       "      <td>True</td>\n",
       "      <td>low O2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>241 days</td>\n",
       "      <td>20171218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2608</th>\n",
       "      <td>AC000W002450261</td>\n",
       "      <td>2018-11-28</td>\n",
       "      <td>True</td>\n",
       "      <td>high HR</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>245 days</td>\n",
       "      <td>20180328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945</th>\n",
       "      <td>AC000W001105945</td>\n",
       "      <td>2017-08-20</td>\n",
       "      <td>True, low baseline</td>\n",
       "      <td>low O2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>105 days</td>\n",
       "      <td>20170507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3030</th>\n",
       "      <td>AC000W002665005</td>\n",
       "      <td>2018-12-11</td>\n",
       "      <td>True</td>\n",
       "      <td>low O2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>113 days</td>\n",
       "      <td>20180820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3616</th>\n",
       "      <td>AC000W001054681</td>\n",
       "      <td>2017-09-08</td>\n",
       "      <td>True</td>\n",
       "      <td>high HR</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>90 days</td>\n",
       "      <td>20170610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6256</th>\n",
       "      <td>AC000W000400907</td>\n",
       "      <td>2018-01-19</td>\n",
       "      <td>True, low baseline</td>\n",
       "      <td>low O2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>6 days</td>\n",
       "      <td>20180113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6339</th>\n",
       "      <td>AC000W001045152</td>\n",
       "      <td>2017-12-23</td>\n",
       "      <td>True</td>\n",
       "      <td>low O2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3 days</td>\n",
       "      <td>20171220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6612</th>\n",
       "      <td>AC000W002669445</td>\n",
       "      <td>2018-08-21</td>\n",
       "      <td>True</td>\n",
       "      <td>low O2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>52 days</td>\n",
       "      <td>20180630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8426</th>\n",
       "      <td>AC000W002629712</td>\n",
       "      <td>2018-10-17</td>\n",
       "      <td>True</td>\n",
       "      <td>low O2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>86 days</td>\n",
       "      <td>20180723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9286</th>\n",
       "      <td>AC000W002633086</td>\n",
       "      <td>2018-09-27</td>\n",
       "      <td>True</td>\n",
       "      <td>low O2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>79 days</td>\n",
       "      <td>20180710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dsn        date      critical_event last_10_minutes  cc  \\\n",
       "74    AC000W001060959  2018-02-12  True, low baseline          low O2   0   \n",
       "600   AC000W001087323  2017-03-13  True, low baseline          low O2   0   \n",
       "978   AC000W001041852  2018-02-26  True, low baseline          low O2   1   \n",
       "1038  AC000W001205802  2018-11-05                True          low O2   1   \n",
       "1092  AC000W001066401  2018-07-11                True          low O2   0   \n",
       "1117  AC000W001052267  2017-10-20                True          low O2   1   \n",
       "1442  AC000W000505417  2017-05-01  True, low baseline          low O2   1   \n",
       "1743  AC000W001067140  2017-11-09                True          low O2   0   \n",
       "2607  AC000W002575870  2018-08-16                True          low O2   1   \n",
       "2608  AC000W002450261  2018-11-28                True         high HR   1   \n",
       "2945  AC000W001105945  2017-08-20  True, low baseline          low O2   0   \n",
       "3030  AC000W002665005  2018-12-11                True          low O2   0   \n",
       "3616  AC000W001054681  2017-09-08                True         high HR   1   \n",
       "6256  AC000W000400907  2018-01-19  True, low baseline          low O2   1   \n",
       "6339  AC000W001045152  2017-12-23                True          low O2   0   \n",
       "6612  AC000W002669445  2018-08-21                True          low O2   1   \n",
       "8426  AC000W002629712  2018-10-17                True          low O2   0   \n",
       "9286  AC000W002633086  2018-09-27                True          low O2   0   \n",
       "\n",
       "      at_risk_or_issues baby_age  birthday  \n",
       "74                False 251 days  20170606  \n",
       "600               False  21 days  20170220  \n",
       "978               False 324 days  20170408  \n",
       "1038              False 165 days  20180524  \n",
       "1092              False 186 days  20180106  \n",
       "1117              False   9 days  20171011  \n",
       "1442              False   2 days  20170429  \n",
       "1743              False  10 days  20171030  \n",
       "2607              False 241 days  20171218  \n",
       "2608              False 245 days  20180328  \n",
       "2945              False 105 days  20170507  \n",
       "3030              False 113 days  20180820  \n",
       "3616              False  90 days  20170610  \n",
       "6256              False   6 days  20180113  \n",
       "6339              False   3 days  20171220  \n",
       "6612              False  52 days  20180630  \n",
       "8426              False  86 days  20180723  \n",
       "9286              False  79 days  20180710  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true = ['True', 'True, low baseline', 'True, instantaneous', 'True, many instantaneous']\n",
    "df_classified.query('critical_event in @true and at_risk_or_issues == False and last_10_minutes != \"Good vitals\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pull 2 sec data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "301669ee25f740c3b8dd1981c6963179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "905c64bd8b384d22baf23af6d9675ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Pull 2 sec data onto my drive?\n",
    "true = ['True', 'True, low baseline', 'True, instantaneous', 'True, many instantaneous']\n",
    "df_critical = df_classified.query('critical_event in @true and at_risk_or_issues == False')\n",
    "critical_dsns = df_critical.dsn.unique().tolist()\n",
    "df_fullpath = pd.read_sql(\"\"\"select * from devices where dsn in %(d)s\"\"\", conn, params={'d':critical_dsns})\n",
    "df_fullpath = df_fullpath[['dsn','fullpath','masknum']]\n",
    "\n",
    "directories = []\n",
    "for day in tqdm_notebook(df_critical.date.unique().tolist()):\n",
    "    date = str(day).replace('-','')\n",
    "    directories.append(date)\n",
    "\n",
    "# import os\n",
    "# for file in directories:\n",
    "#     os.system(f\"mkdir ~/Documents/Owlet-code/{folder}/{file}\")\n",
    "\n",
    "commands = []\n",
    "for dsn, day in tqdm_notebook(zip(df_critical.dsn.tolist(),df_critical.date.tolist())):\n",
    "    day = str(day).replace('-','')\n",
    "    path = df_fullpath[df_fullpath.dsn == dsn].fullpath.values[0]\n",
    "    folder_num = df_fullpath[df_fullpath.dsn == dsn].masknum.values[0]\n",
    "\n",
    "    # ***Change destination to round folder/16000_2sec\n",
    "    line = f'get {path}/{dsn}_{day}* ~/Documents/Owlet-code/{folder}/16000_2sec/{day}/{dsn}.csv.gz' \n",
    "    commands.append(line)\n",
    "\n",
    "# Paste these commands in sftp bigmama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Once I have 2 second data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dont want to apply this to whole df, just to critical events (have to get 2sec data on computer before)\n",
    "if df_critical.shape[0] != 0:\n",
    "    df_critical['signal_sock'] = df_critical.apply(signal_sock, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakdown of classifications: ** * ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** cases \n",
    "\n",
    "df_critical[(df_critical.at_risk_or_issues == False) &\n",
    "            (df_critical.last_10_minutes != 'Good vitals') &\n",
    "            (df_critical.critical_event != 'True, instantaneous') &\n",
    "            (df_critical.critical_event != 'True, many instantaneous') &\n",
    "            (df_critical.signal_sock != 'sock off') &\n",
    "            (df_critical.signal_sock != 'data cut off')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * cases\n",
    "\n",
    "df_critical[(df_critical.at_risk_or_issues == False) &\n",
    "            (df_critical.last_10_minutes != 'Good vitals') &\n",
    "            (df_critical.critical_event != 'True, instantaneous') &\n",
    "            (df_critical.signal_sock != 'signal lost before sock off') &\n",
    "            (df_critical.signal_sock != 'unknown') &\n",
    "            (df_critical.signal_sock != 'battery died')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ? cases\n",
    "\n",
    "df_critical[(df_critical.at_risk_or_issues == False) &\n",
    "            (((df_critical.last_10_minutes != 'Good vitals') &\n",
    "            ((df_critical.critical_event == 'True, instantaneous') &\n",
    "            (df_critical.signal_sock != 'sock off'))) |\n",
    "            (df_critical.critical_event == 'True, many instantaneous'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 second data still needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_critical[df_critical.signal_sock == 'Need data']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
