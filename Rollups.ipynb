{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import gzip\n",
    "import timeit\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "from functools import partial\n",
    "from pandas.tseries.frequencies import to_offset\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "data_folder = './samplecsvdata/'\n",
    "fs = os.listdir(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load sleep model\n",
    "sleep_model_path = './SleepModel10Min.sav'\n",
    "sleep_clfr = pickle.load(open(sleep_model_path, 'rb'))\n",
    "\n",
    "#load norm data\n",
    "sleep_norms = pd.read_csv('sleep_norms.csv', index_col=0)\n",
    "\n",
    "#define sleep feature columns\n",
    "feature_columns = ['count', 'valid_count', 'movement_raw_mean', 'movement_raw_min',\n",
    "   'movement_raw_max', 'movement_raw_std', 'heart_rate_raw_mean',\n",
    "   'heart_rate_raw_min', 'heart_rate_raw_max', 'heart_rate_raw_std', 'oxygen_raw_mean',\n",
    "   'oxygen_raw_min', 'oxygen_raw_max', 'oxygen_raw_std']\n",
    "\n",
    "def roll_up_ten(df):\n",
    "    df = df.copy().drop_duplicates('timestamp')\n",
    "    #clean data\n",
    "    df.index = pd.to_datetime(df.timestamp, utc=True, unit='s')\n",
    "    df = df[(df.base_state>=4) & (df.ble_rssi !=0) & (df.heart_rate_raw >0)]\n",
    "    df_valid = df[(df.notification_mask == 0) & (df.heart_rate_raw > 0)]\n",
    "    \n",
    "#     print(len(df))\n",
    "#     print(len(df_valid))\n",
    "\n",
    "    #make at least 1 row so the dataframes can be merged later\n",
    "    if(len(df_valid)==0 and len(df)>0):\n",
    "        df_valid.loc[df.index[0]] = np.NaN\n",
    "        \n",
    "    #dsn,count\n",
    "    group = df[['dsn']].resample(\"10T\")\n",
    "    df_dsn = group.apply(['first','count'])\n",
    "    df_dsn.columns = ['dsn','count']\n",
    "    \n",
    "    \n",
    "    #valid count this has an issue\n",
    "    def count_valid_reads(array_like):\n",
    "        return np.sum(array_like == 0)\n",
    "\n",
    "    group = df[['notification_mask']].resample(\"10T\")\n",
    "    df_valid_count = group.apply(count_valid_reads)\n",
    "    df_valid_count.columns = ['valid_count']\n",
    "    \n",
    "    #base state\n",
    "    def base_state_4(array_like): return 4 in array_like.values\n",
    "    def base_state_6(array_like): return 6 in array_like.values\n",
    "    def base_state_7(array_like): return 7 in array_like.values\n",
    "    def base_state_8(array_like): return 8 in array_like.values\n",
    "    def base_state_9(array_like): return 9 in array_like.values\n",
    "    def base_state_10(array_like): return 10 in array_like.values\n",
    "    def base_state_12(array_like): return 12 in array_like.values\n",
    "    \n",
    "    group = df[['base_state']].resample(\"10T\")\n",
    "    df_states = group.apply([base_state_4,base_state_6,base_state_7,base_state_8,base_state_9,base_state_10,base_state_12])\n",
    "        \n",
    "    df_states.columns = [col[1] for col in df_states.columns.values]\n",
    "    \n",
    "    #aggregate over columns that don't require valid data\n",
    "    agg_cols = [\n",
    "        'movement_raw', \n",
    "        'skin_temperature',\n",
    "        'red_led_current',\n",
    "        'ir_led_current',\n",
    "        'ble_rssi',\n",
    "        'battery_level',\n",
    "    ]\n",
    "    group = df[agg_cols].resample(\"10T\")\n",
    "    df_agg = group.apply(['mean','min','max','std'])\n",
    "    df_agg.columns = ['_'.join(col).strip() for col in df_agg.columns.values]\n",
    "    \n",
    "    #aggregate over columns that do require valid data\n",
    "    valid_agg_cols = [\n",
    "        'heart_rate_avg',\n",
    "        'heart_rate_raw', \n",
    "        'oxygen_avg', \n",
    "        'oxygen_raw' \n",
    "    ]\n",
    "    group = df_valid[valid_agg_cols].resample(\"10T\")\n",
    "    df_agg_valid = group.apply(['mean','min','max','std'])\n",
    "    df_agg_valid.columns = ['_'.join(col).strip() for col in df_agg_valid.columns.values]\n",
    "    \n",
    "    df_rolled = pd.concat([df_dsn,df_valid_count,df_agg,df_agg_valid,df_states],axis = 1)\n",
    "    \n",
    "    #add sleep\n",
    "    if(len(df_rolled)==0):\n",
    "        df_rolled['sleep_states'] = np.nan\n",
    "    else:\n",
    "        features = df_rolled[feature_columns].apply(pd.to_numeric).fillna(method='ffill').fillna(method='bfill')\n",
    "        features = (features - sleep_norms.m)/sleep_norms.s\n",
    "        df_rolled['sleep_states'] = sleep_clfr.predict(features.values)\n",
    "\n",
    "    return df_rolled.dropna(subset=['dsn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113 ms ± 1.19 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "col_names = pd.read_csv('column_names.txt').columns\n",
    "df = pd.read_csv(data_folder + fs[0], names=col_names)\n",
    "# %lprun -f roll_up_ten roll_up_ten(df)\n",
    "df_rolled = roll_up_ten(df)\n",
    "df_rolled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This roll_up_ten eliminates possible resample calls (all but 2) and uses separate agg calls to apply different functions to each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load sleep model\n",
    "sleep_model_path = './SleepModel10Min.sav'\n",
    "sleep_clfr = pickle.load(open(sleep_model_path, 'rb'))\n",
    "\n",
    "#load norm data\n",
    "sleep_norms = pd.read_csv('sleep_norms.csv', index_col=0)\n",
    "\n",
    "#define sleep feature columns\n",
    "feature_columns = ['count', 'valid_count', 'movement_raw_mean', 'movement_raw_min',\n",
    "   'movement_raw_max', 'movement_raw_std', 'heart_rate_raw_mean',\n",
    "   'heart_rate_raw_min', 'heart_rate_raw_max', 'heart_rate_raw_std', 'oxygen_raw_mean',\n",
    "   'oxygen_raw_min', 'oxygen_raw_max', 'oxygen_raw_std']\n",
    "\n",
    "def roll_up_ten(df):\n",
    "    df = df.drop_duplicates('timestamp')\n",
    "    #clean data\n",
    "    df.index = pd.to_datetime(df.timestamp, utc=True, unit='s')\n",
    "    df = df[(df.base_state>=4) & (df.ble_rssi !=0) & (df.heart_rate_raw >0)]\n",
    "    df_valid = df[(df.notification_mask == 0) & (df.heart_rate_raw > 0)]\n",
    "\n",
    "    #make at least 1 row so the dataframes can be merged later\n",
    "    if(len(df_valid)==0 and len(df)>0):\n",
    "        df_valid.loc[df.index[0]] = np.NaN\n",
    "   \n",
    "    #aggregate over columns that do require valid data\n",
    "    valid_agg_cols = [\n",
    "        'heart_rate_avg',\n",
    "        'heart_rate_raw', \n",
    "        'oxygen_avg', \n",
    "        'oxygen_raw' \n",
    "    ]\n",
    "\n",
    "    # Resample\n",
    "    group = df.resample(\"10T\")\n",
    "    group_valid = df_valid[valid_agg_cols].resample(\"10T\")\n",
    "    \n",
    "    #dsn,count\n",
    "    df_dsn = group.agg({'dsn':['first','count']})\n",
    "    df_dsn.columns = ['dsn','count']\n",
    "       \n",
    "    #valid count this has an issue\n",
    "    def count_valid_reads(array_like):\n",
    "        return np.sum(array_like == 0)\n",
    "\n",
    "    df_valid_count = group.agg({'notification_mask':count_valid_reads})\n",
    "    df_valid_count.columns = ['valid_count']\n",
    "    \n",
    "    #base state\n",
    "    def base_state_4(array_like): return 4 in array_like.values\n",
    "    def base_state_6(array_like): return 6 in array_like.values\n",
    "    def base_state_7(array_like): return 7 in array_like.values\n",
    "    def base_state_8(array_like): return 8 in array_like.values\n",
    "    def base_state_9(array_like): return 9 in array_like.values\n",
    "    def base_state_10(array_like): return 10 in array_like.values\n",
    "    def base_state_12(array_like): return 12 in array_like.values\n",
    "    \n",
    "    df_states = group.agg({'base_state':[base_state_4,base_state_6,base_state_7,base_state_8,base_state_9,base_state_10,base_state_12]})       \n",
    "    df_states.columns = [col[1] for col in df_states.columns.values]\n",
    "\n",
    "    #aggregate over columns that don't require valid data\n",
    "    agg_cols = [\n",
    "        'movement_raw', \n",
    "        'skin_temperature',\n",
    "        'red_led_current',\n",
    "        'ir_led_current',\n",
    "        'ble_rssi',\n",
    "        'battery_level',\n",
    "    ]\n",
    "    df_agg = group.agg({col:['mean','min','max','std'] for col in agg_cols})\n",
    "    df_agg.columns = ['_'.join(col).strip() for col in df_agg.columns.values]\n",
    "    \n",
    "    \n",
    "    df_agg_valid = group_valid.apply(['mean','min','max','std'])\n",
    "    df_agg_valid.columns = ['_'.join(col).strip() for col in df_agg_valid.columns.values]\n",
    "    \n",
    "    df_rolled = pd.concat([df_dsn,df_valid_count,df_agg,df_agg_valid,df_states],axis = 1)\n",
    "    \n",
    "    #add sleep\n",
    "    if(len(df_rolled)==0):\n",
    "        df_rolled['sleep_states'] = np.nan\n",
    "    else:\n",
    "        features = df_rolled[feature_columns].apply(pd.to_numeric).fillna(method='ffill').fillna(method='bfill')\n",
    "        features = (features - sleep_norms.m)/sleep_norms.s\n",
    "        df_rolled['sleep_states'] = sleep_clfr.predict(features.values)\n",
    "\n",
    "    return df_rolled.dropna(subset=['dsn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 ms ± 7.74 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "col_names = pd.read_csv('column_names.txt').columns\n",
    "df = pd.read_csv(data_folder + fs[0], names=col_names)\n",
    "# %lprun -f roll_up_ten roll_up_ten(df)\n",
    "df_rolled = roll_up_ten(df)\n",
    "df_rolled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This roll_up_ten eliminates possible .resample calls (all but 2) but uses 1 .agg call and 1 .apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load sleep model\n",
    "sleep_model_path = './SleepModel10Min.sav'\n",
    "sleep_clfr = pickle.load(open(sleep_model_path, 'rb'))\n",
    "\n",
    "#load norm data\n",
    "sleep_norms = pd.read_csv('sleep_norms.csv', index_col=0)\n",
    "\n",
    "#define sleep feature columns\n",
    "feature_columns = ['count', 'valid_count', 'movement_raw_mean', 'movement_raw_min',\n",
    "   'movement_raw_max', 'movement_raw_std', 'heart_rate_raw_mean',\n",
    "   'heart_rate_raw_min', 'heart_rate_raw_max', 'heart_rate_raw_std', 'oxygen_raw_mean',\n",
    "   'oxygen_raw_min', 'oxygen_raw_max', 'oxygen_raw_std']\n",
    "\n",
    "def roll_up_ten(df):\n",
    "    df = df.drop_duplicates('timestamp')\n",
    "    #clean data\n",
    "    df.index = pd.to_datetime(df.timestamp, utc=True, unit='s')\n",
    "    df = df[(df.base_state>=4) & (df.ble_rssi !=0) & (df.heart_rate_raw >0)]\n",
    "    df_valid = df[(df.notification_mask == 0) & (df.heart_rate_raw > 0)]    \n",
    "\n",
    "    #make at least 1 row so the dataframes can be merged later\n",
    "    if(len(df_valid)==0 and len(df)>0):\n",
    "        df_valid.loc[df.index[0]] = np.NaN\n",
    "              \n",
    "    #valid count this has an issue\n",
    "    def count_valid_reads(array_like):\n",
    "        return np.sum(array_like == 0)\n",
    "    \n",
    "    #base state\n",
    "    def base_state_4(array_like): return 4 in array_like.values\n",
    "    def base_state_6(array_like): return 6 in array_like.values\n",
    "    def base_state_7(array_like): return 7 in array_like.values\n",
    "    def base_state_8(array_like): return 8 in array_like.values\n",
    "    def base_state_9(array_like): return 9 in array_like.values\n",
    "    def base_state_10(array_like): return 10 in array_like.values\n",
    "    def base_state_12(array_like): return 12 in array_like.values\n",
    "    \n",
    "    #aggregate over columns that don't require valid data\n",
    "    agg_cols = [\n",
    "        'movement_raw', \n",
    "        'skin_temperature',\n",
    "        'red_led_current',\n",
    "        'ir_led_current',\n",
    "        'ble_rssi',\n",
    "        'battery_level',\n",
    "    ]\n",
    "    \n",
    "    #aggregate over columns that do require valid data\n",
    "    valid_agg_cols = [\n",
    "        'heart_rate_avg',\n",
    "        'heart_rate_raw', \n",
    "        'oxygen_avg', \n",
    "        'oxygen_raw' \n",
    "    ]\n",
    "    \n",
    "    # Resample\n",
    "    group = df.resample(\"10T\")\n",
    "    group_valid = df_valid[valid_agg_cols].resample(\"10T\")\n",
    "    \n",
    "    functions_to_apply = {'dsn':['first','count'], 'notification_mask':count_valid_reads, \n",
    "                          'base_state':[base_state_4,base_state_6,base_state_7,base_state_8,base_state_9,base_state_10,base_state_12]}\n",
    "    functions_to_apply.update({col:['mean','min','max','std'] for col in agg_cols})\n",
    "    df1 = group.agg(functions_to_apply)\n",
    "    \n",
    "    # valid data\n",
    "    df_agg_valid = group_valid.apply(['mean','min','max','std'])\n",
    "    df_agg_valid.columns = ['_'.join(col).strip() for col in df_agg_valid.columns.values]\n",
    "\n",
    "    # column names\n",
    "    df1.columns = ['dsn','count','valid_count', 'base_state_4', 'base_state_6', 'base_state_7', 'base_state_8',\n",
    "                   'base_state_9', 'base_state_10', 'base_state_12', 'movement_raw_mean', 'movement_raw_min', \n",
    "                   'movement_raw_max','movement_raw_std', 'skin_temperature_mean', 'skin_temperature_min',\n",
    "                   'skin_temperature_max', 'skin_temperature_std', 'red_led_current_mean','red_led_current_min', \n",
    "                   'red_led_current_max', 'red_led_current_std', 'ir_led_current_mean', 'ir_led_current_min', \n",
    "                   'ir_led_current_max','ir_led_current_std', 'ble_rssi_mean', 'ble_rssi_min', 'ble_rssi_max',\n",
    "                   'ble_rssi_std', 'battery_level_mean', 'battery_level_min', 'battery_level_max', 'battery_level_std']\n",
    "\n",
    "    df_rolled = pd.concat([df,df_agg_valid],axis = 1)\n",
    "    \n",
    "    \n",
    "    #add sleep\n",
    "    if(len(df_rolled)==0):\n",
    "        df_rolled['sleep_states'] = np.nan\n",
    "    else:\n",
    "        features = df_rolled[feature_columns].apply(pd.to_numeric).fillna(method='ffill').fillna(method='bfill')\n",
    "        features = (features - sleep_norms.m)/sleep_norms.s\n",
    "        df_rolled['sleep_states'] = sleep_clfr.predict(features.values)\n",
    "\n",
    "    return df_rolled.dropna(subset=['dsn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 ms ± 997 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "col_names = pd.read_csv('column_names.txt').columns\n",
    "df = pd.read_csv(data_folder + fs[0], names=col_names)\n",
    "# %lprun -f roll_up_ten roll_up_ten(df)\n",
    "df_rolled = roll_up_ten(df)\n",
    "df_rolled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rolled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "%%prun\n",
    "df_rolled = roll_up_ten(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# df = pd.read_csv(data_folder + fs[0], names=col_names)\n",
    "# df_rolled = roll_up_ten(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "valid_agg_cols = [\n",
    "    'heart_rate_avg',\n",
    "    'heart_rate_raw', \n",
    "    'oxygen_avg', \n",
    "    'oxygen_raw' \n",
    "]\n",
    "\n",
    "my_df = pd.read_csv('../mask9_2018/20181120/AC000W001055137.csv.gz', names=col_names) #bad data\n",
    "# my_df = pd.read_csv('../mask9_2018/20181120/AC000W000652029.csv.gz', names=col_names) #good data\n",
    "df = my_df.copy()\n",
    "df = df.drop_duplicates('timestamp')\n",
    "\n",
    "#clean data\n",
    "df.index = pd.to_datetime(df.timestamp, utc=True, unit='s')\n",
    "df = df[(df.base_state>=4) & (df.ble_rssi !=0) & (df.heart_rate_raw >0)]\n",
    "df[valid_agg_cols][(df.notification_mask == 0) & (df.heart_rate_raw > 0)] = np.nan\n",
    "\n",
    "if(len(df) == 0):\n",
    "    print('oops') \n",
    "\n",
    "\n",
    "#dsn,count\n",
    "group = df[['dsn']].resample(\"10T\")\n",
    "print(len(group))\n",
    "%time df_dsn = group.apply(['first','count'])\n",
    "df_dsn.columns = ['dsn','count']\n",
    "\n",
    "\n",
    "#base state\n",
    "def base_state_4(array_like): return 4 in array_like.values\n",
    "def base_state_6(array_like): return 6 in array_like.values\n",
    "def base_state_7(array_like): return 7 in array_like.values\n",
    "def base_state_8(array_like): return 8 in array_like.values\n",
    "def base_state_9(array_like): return 9 in array_like.values\n",
    "def base_state_10(array_like): return 10 in array_like.values\n",
    "def base_state_12(array_like): return 12 in array_like.values\n",
    "\n",
    "group = df[['base_state']].resample(\"10T\")\n",
    "df_states = group.apply([base_state_4,base_state_6,base_state_7,base_state_8,base_state_9,base_state_10,base_state_12])\n",
    "\n",
    "df_states.columns = [col[1] for col in df_states.columns.values]\n",
    "\n",
    "#aggregate over columns that don't require valid data\n",
    "agg_cols = [\n",
    "    'movement_raw', \n",
    "    'skin_temperature',\n",
    "    'red_led_current',\n",
    "    'ir_led_current',\n",
    "    'ble_rssi',\n",
    "    'battery_level',\n",
    "    'heart_rate_avg',\n",
    "    'heart_rate_raw', \n",
    "    'oxygen_avg', \n",
    "    'oxygen_raw' \n",
    "]\n",
    "group = df[agg_cols].resample(\"10T\")\n",
    "df_agg = group.apply(['mean','min','max','std'])\n",
    "df_agg.columns = ['_'.join(col).strip() for col in df_agg.columns.values]\n",
    "\n",
    "\n",
    "#add sleep\n",
    "if(len(df_rolled)==0):\n",
    "    df_rolled['sleep_states'] = np.nan\n",
    "else:\n",
    "    features = df_rolled[feature_columns].apply(pd.to_numeric).fillna(method='ffill').fillna(method='bfill')\n",
    "    features = (features - sleep_norms.m)/sleep_norms.s\n",
    "    df_rolled['sleep_states'] = sleep_clfr.predict(features.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(df_rolled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#good\n",
    "my_df = pd.read_csv('../mask9_2018/20180101/AC000W000423061.csv.gz', names=col_names) #good data\n",
    "my_df = my_df.copy().sort_values('timestamp').reset_index()\n",
    "df = my_df.copy()\n",
    "#clean data\n",
    "df.index = pd.to_datetime(df.timestamp, utc=True, unit='s')\n",
    "df = df[(df.base_state>=4) & (df.ble_rssi !=0) & (df.heart_rate_raw >0)]\n",
    "df_valid = df[(df.notification_mask == 0) & (df.heart_rate_raw > 0)]\n",
    "df_valid.plot(x=['timestamp','timestamp'], y=['heart_rate_raw', 'movement_raw'], kind='scatter')\n",
    "plt.show()\n",
    "df.plot(x=['timestamp','timestamp'], y=['heart_rate_raw', 'movement_raw'], kind='scatter')\n",
    "plt.show()\n",
    "my_df.plot(x=['timestamp','timestamp'], y=['heart_rate_raw', 'movement_raw'], kind='scatter')\n",
    "plt.show()\n",
    "print(len(my_df))\n",
    "print(len(df))\n",
    "print(len(df_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bad\n",
    "# my_df = pd.read_csv('../mask9_2018/20181120/AC000W001055137.csv.gz', names=col_names) #bad data\n",
    "my_df = pd.read_csv('../mask9_2018/20180101/AC000W001144880.csv.gz', names=col_names) #bad data\n",
    "\n",
    "my_df = my_df.copy().sort_values('timestamp').reset_index()\n",
    "df = my_df.copy()\n",
    "#clean data\n",
    "df.index = pd.to_datetime(df.timestamp, utc=True, unit='s')\n",
    "df = df[(df.base_state>=4) & (df.ble_rssi !=0) & (df.heart_rate_raw >0)]\n",
    "df_valid = df[(df.notification_mask == 0) & (df.heart_rate_raw > 0)]\n",
    "df_valid.plot(x=['timestamp','timestamp'], y=['heart_rate_raw', 'movement_raw'], kind='scatter')\n",
    "plt.show()\n",
    "df.plot(x=['timestamp','timestamp'], y=['heart_rate_raw', 'movement_raw'], kind='scatter')\n",
    "plt.show()\n",
    "my_df.plot(x=['timestamp','timestamp'], y=['heart_rate_raw', 'movement_raw'], kind='scatter')\n",
    "plt.show()\n",
    "print(len(my_df))\n",
    "print(len(df))\n",
    "print(len(df_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.sort_values('timestamp').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rolled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rolled.loc['2018-11-20 23:50:00+00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data_folder = '../mask9_2018/'\n",
    "all_dirs = os.listdir(log_data_folder)\n",
    "all_dirs.sort()\n",
    "print(all_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data_folder = '../mask9_2018/'\n",
    "all_dirs = os.listdir(log_data_folder)\n",
    "all_dirs.sort()\n",
    "count = 0\n",
    "for d in all_dirs:\n",
    "    count += 1\n",
    "    print(d)\n",
    "    all_files = os.listdir(log_data_folder+d)\n",
    "    for f in all_files:\n",
    "        tic = timeit.default_timer()\n",
    "        p = log_data_folder + d + '/' + f\n",
    "        df = pd.read_csv(p, names=col_names)\n",
    "        df_rolled = roll_up_ten(df)\n",
    "        if(len(df_rolled) > 0):\n",
    "            dp = '../mask9_2018_rolled2/' + df_rolled['dsn'][0] +'.csv.gz'\n",
    "            df_rolled.to_csv(dp, mode='a', header=False, compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
