{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import gzip\n",
    "import timeit\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "from functools import partial\n",
    "from pandas.tseries.frequencies import to_offset\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "data_folder = './samplecsvdata/'\n",
    "fs = os.listdir(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This roll_up_ten eliminates possible resample calls (all but 2) and uses separate agg calls to apply different functions to each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load sleep model\n",
    "sleep_model_path = './SleepModel10Min.sav'\n",
    "sleep_clfr = pickle.load(open(sleep_model_path, 'rb'))\n",
    "\n",
    "#load norm data\n",
    "sleep_norms = pd.read_csv('sleep_norms.csv', index_col=0)\n",
    "\n",
    "#define sleep feature columns\n",
    "feature_columns = ['count', 'valid_count', 'movement_raw_mean', 'movement_raw_min',\n",
    "   'movement_raw_max', 'movement_raw_std', 'heart_rate_raw_mean',\n",
    "   'heart_rate_raw_min', 'heart_rate_raw_max', 'heart_rate_raw_std', 'oxygen_raw_mean',\n",
    "   'oxygen_raw_min', 'oxygen_raw_max', 'oxygen_raw_std']\n",
    "\n",
    "def roll_up_ten(df):\n",
    "    df = df.copy().drop_duplicates('timestamp')\n",
    "    #clean data\n",
    "    df.index = pd.to_datetime(df.timestamp, utc=True, unit='s')\n",
    "    df = df[(df.base_state>=4) & (df.ble_rssi !=0) & (df.heart_rate_raw >0)]\n",
    "    df_valid = df[(df.notification_mask == 0) & (df.heart_rate_raw > 0)]\n",
    "\n",
    "    #make at least 1 row so the dataframes can be merged later\n",
    "    if(len(df_valid)==0 and len(df)>0):\n",
    "        df_valid.loc[df.index[0]] = np.NaN\n",
    "                \n",
    "    # Resample\n",
    "    group = df.resample(\"10T\")\n",
    "    group_valid = df_valid[valid_agg_cols].resample(\"10T\")\n",
    "    \n",
    "    #dsn,count\n",
    "    df_dsn = group.agg({'dsn':['first','count']})\n",
    "    df_dsn.columns = ['dsn','count']\n",
    "       \n",
    "    #valid count this has an issue\n",
    "    def count_valid_reads(array_like):\n",
    "        return np.sum(array_like == 0)\n",
    "\n",
    "    df_valid_count = group.agg({'notification_mask':count_valid_reads})\n",
    "    df_valid_count.columns = ['valid_count']\n",
    "    \n",
    "    #base state\n",
    "    def base_state_4(array_like): return 4 in array_like.values\n",
    "    def base_state_6(array_like): return 6 in array_like.values\n",
    "    def base_state_7(array_like): return 7 in array_like.values\n",
    "    def base_state_8(array_like): return 8 in array_like.values\n",
    "    def base_state_9(array_like): return 9 in array_like.values\n",
    "    def base_state_10(array_like): return 10 in array_like.values\n",
    "    def base_state_12(array_like): return 12 in array_like.values\n",
    "    \n",
    "    df_states = group.agg({'base_state':[base_state_4,base_state_6,base_state_7,base_state_8,base_state_9,base_state_10,base_state_12]})       \n",
    "    df_states.columns = [col[1] for col in df_states.columns.values]\n",
    "    \n",
    "    #aggregate over columns that don't require valid data\n",
    "    agg_cols = [\n",
    "        'movement_raw', \n",
    "        'skin_temperature',\n",
    "        'red_led_current',\n",
    "        'ir_led_current',\n",
    "        'ble_rssi',\n",
    "        'battery_level',\n",
    "    ]\n",
    "    df_agg = group.agg({col:['mean','min','max','std'] for col in agg_cols})\n",
    "    df_agg.columns = ['_'.join(col).strip() for col in df_agg.columns.values]\n",
    "    \n",
    "    #aggregate over columns that do require valid data\n",
    "    valid_agg_cols = [\n",
    "        'heart_rate_avg',\n",
    "        'heart_rate_raw', \n",
    "        'oxygen_avg', \n",
    "        'oxygen_raw' \n",
    "    ]\n",
    "    \n",
    "    df_agg_valid = group_valid.apply(['mean','min','max','std'])\n",
    "    df_agg_valid.columns = ['_'.join(col).strip() for col in df_agg_valid.columns.values]\n",
    "    \n",
    "    df_rolled = pd.concat([df_dsn,df_valid_count,df_agg,df_agg_valid,df_states],axis = 1)\n",
    "    \n",
    "    #add sleep\n",
    "    if(len(df_rolled)==0):\n",
    "        df_rolled['sleep_states'] = np.nan\n",
    "    else:\n",
    "        features = df_rolled[feature_columns].apply(pd.to_numeric).fillna(method='ffill').fillna(method='bfill')\n",
    "        features = (features - sleep_norms.m)/sleep_norms.s\n",
    "        df_rolled['sleep_states'] = sleep_clfr.predict(features.values)\n",
    "\n",
    "    return df_rolled.dropna(subset=['dsn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = pd.read_csv('column_names.txt').columns\n",
    "df = pd.read_csv(data_folder + fs[0], names=col_names)\n",
    "df_rolled = roll_up_ten(df)\n",
    "df_rolled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This roll_up_ten eliminates possible .resample calls (all but 2) but uses 1 .agg call and 1 .apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load sleep model\n",
    "sleep_model_path = './SleepModel10Min.sav'\n",
    "# sleep_clfr = pickle.load(open(sleep_model_path, 'rb'))\n",
    "\n",
    "#load norm data\n",
    "# sleep_norms = pd.read_csv('sleep_norms.csv', index_col=0)\n",
    "\n",
    "#define sleep feature columns\n",
    "feature_columns = ['count', 'valid_count', 'movement_raw_mean', 'movement_raw_min',\n",
    "   'movement_raw_max', 'movement_raw_std', 'heart_rate_raw_mean',\n",
    "   'heart_rate_raw_min', 'heart_rate_raw_max', 'heart_rate_raw_std', 'oxygen_raw_mean',\n",
    "   'oxygen_raw_min', 'oxygen_raw_max', 'oxygen_raw_std']\n",
    "\n",
    "def roll_up_ten(df):\n",
    "    df = df.copy().drop_duplicates('timestamp')\n",
    "    #clean data\n",
    "    df.index = pd.to_datetime(df.timestamp, utc=True, unit='s')\n",
    "    df = df[(df.base_state>=4) & (df.ble_rssi !=0) & (df.heart_rate_raw >0)]\n",
    "    df_valid = df[(df.notification_mask == 0) & (df.heart_rate_raw > 0)]    \n",
    "\n",
    "    #make at least 1 row so the dataframes can be merged later\n",
    "    if(len(df_valid)==0 and len(df)>0):\n",
    "        df_valid.loc[df.index[0]] = np.NaN\n",
    "              \n",
    "    #valid count this has an issue\n",
    "    def count_valid_reads(array_like):\n",
    "        return np.sum(array_like == 0)\n",
    "    \n",
    "    #base state\n",
    "    def base_state_4(array_like): return 4 in array_like.values\n",
    "    def base_state_6(array_like): return 6 in array_like.values\n",
    "    def base_state_7(array_like): return 7 in array_like.values\n",
    "    def base_state_8(array_like): return 8 in array_like.values\n",
    "    def base_state_9(array_like): return 9 in array_like.values\n",
    "    def base_state_10(array_like): return 10 in array_like.values\n",
    "    def base_state_12(array_like): return 12 in array_like.values\n",
    "    \n",
    "    #aggregate over columns that don't require valid data\n",
    "    agg_cols = [\n",
    "        'movement_raw', \n",
    "        'skin_temperature',\n",
    "        'red_led_current',\n",
    "        'ir_led_current',\n",
    "        'ble_rssi',\n",
    "        'battery_level',\n",
    "    ]\n",
    "    \n",
    "    #aggregate over columns that do require valid data\n",
    "    valid_agg_cols = [\n",
    "        'heart_rate_avg',\n",
    "        'heart_rate_raw', \n",
    "        'oxygen_avg', \n",
    "        'oxygen_raw' \n",
    "    ]\n",
    "    \n",
    "    # Resample\n",
    "    group = df.resample(\"10T\")\n",
    "    group_valid = df_valid[valid_agg_cols].resample(\"10T\")\n",
    "    \n",
    "    functions_to_apply = {'dsn':['first','count'], 'notification_mask':count_valid_reads, \n",
    "                          'base_state':[base_state_4,base_state_6,base_state_7,base_state_8,base_state_9,base_state_10,base_state_12]}\n",
    "    functions_to_apply.update({col:['mean','min','max','std'] for col in agg_cols})\n",
    "    df1 = group.agg(functions_to_apply)\n",
    "    \n",
    "    # valid data\n",
    "    df_agg_valid = group_valid.apply(['mean','min','max','std'])\n",
    "    df_agg_valid.columns = ['_'.join(col).strip() for col in df_agg_valid.columns.values]\n",
    "\n",
    "    # Figure out how to get correct column names\n",
    "#     df_dsn.columns = ['dsn','count']\n",
    "#     df_valid_count.columns = ['valid_count']\n",
    "#     df_states.columns = [col[1] for col in df_states.columns.values]\n",
    "#     df_agg.columns = ['_'.join(col).strip() for col in df_agg.columns.values]\n",
    "\n",
    "    df_rolled = pd.concat([df,df_agg_valid],axis = 1)\n",
    "    \n",
    "#     add sleep\n",
    "#     if(len(df_rolled)==0):\n",
    "#         df_rolled['sleep_states'] = np.nan\n",
    "#     else:\n",
    "#         features = df_rolled[feature_columns].apply(pd.to_numeric).fillna(method='ffill').fillna(method='bfill')\n",
    "#         features = (features - sleep_norms.m)/sleep_norms.s\n",
    "#         df_rolled['sleep_states'] = sleep_clfr.predict(features.values)\n",
    "\n",
    "    return df_rolled#.dropna(subset=['dsn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find bottlenecks\n",
    "col_names = pd.read_csv('column_names.txt').columns\n",
    "df = pd.read_csv(data_folder + fs[0], names=col_names)\n",
    "%lprun -f roll_up_ten roll_up_ten(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rolled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%prun\n",
    "df_rolled = roll_up_ten(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# df = pd.read_csv(data_folder + fs[0], names=col_names)\n",
    "# df_rolled = roll_up_ten(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "valid_agg_cols = [\n",
    "    'heart_rate_avg',\n",
    "    'heart_rate_raw', \n",
    "    'oxygen_avg', \n",
    "    'oxygen_raw' \n",
    "]\n",
    "\n",
    "my_df = pd.read_csv('../mask9_2018/20181120/AC000W001055137.csv.gz', names=col_names) #bad data\n",
    "# my_df = pd.read_csv('../mask9_2018/20181120/AC000W000652029.csv.gz', names=col_names) #good data\n",
    "df = my_df.copy()\n",
    "df = df.drop_duplicates('timestamp')\n",
    "\n",
    "#clean data\n",
    "df.index = pd.to_datetime(df.timestamp, utc=True, unit='s')\n",
    "df = df[(df.base_state>=4) & (df.ble_rssi !=0) & (df.heart_rate_raw >0)]\n",
    "df[valid_agg_cols][(df.notification_mask == 0) & (df.heart_rate_raw > 0)] = np.nan\n",
    "\n",
    "if(len(df) == 0):\n",
    "    print('oops') \n",
    "\n",
    "\n",
    "#dsn,count\n",
    "group = df[['dsn']].resample(\"10T\")\n",
    "print(len(group))\n",
    "%time df_dsn = group.apply(['first','count'])\n",
    "df_dsn.columns = ['dsn','count']\n",
    "\n",
    "\n",
    "#base state\n",
    "def base_state_4(array_like): return 4 in array_like.values\n",
    "def base_state_6(array_like): return 6 in array_like.values\n",
    "def base_state_7(array_like): return 7 in array_like.values\n",
    "def base_state_8(array_like): return 8 in array_like.values\n",
    "def base_state_9(array_like): return 9 in array_like.values\n",
    "def base_state_10(array_like): return 10 in array_like.values\n",
    "def base_state_12(array_like): return 12 in array_like.values\n",
    "\n",
    "group = df[['base_state']].resample(\"10T\")\n",
    "df_states = group.apply([base_state_4,base_state_6,base_state_7,base_state_8,base_state_9,base_state_10,base_state_12])\n",
    "\n",
    "df_states.columns = [col[1] for col in df_states.columns.values]\n",
    "\n",
    "#aggregate over columns that don't require valid data\n",
    "agg_cols = [\n",
    "    'movement_raw', \n",
    "    'skin_temperature',\n",
    "    'red_led_current',\n",
    "    'ir_led_current',\n",
    "    'ble_rssi',\n",
    "    'battery_level',\n",
    "    'heart_rate_avg',\n",
    "    'heart_rate_raw', \n",
    "    'oxygen_avg', \n",
    "    'oxygen_raw' \n",
    "]\n",
    "group = df[agg_cols].resample(\"10T\")\n",
    "df_agg = group.apply(['mean','min','max','std'])\n",
    "df_agg.columns = ['_'.join(col).strip() for col in df_agg.columns.values]\n",
    "\n",
    "\n",
    "#add sleep\n",
    "if(len(df_rolled)==0):\n",
    "    df_rolled['sleep_states'] = np.nan\n",
    "else:\n",
    "    features = df_rolled[feature_columns].apply(pd.to_numeric).fillna(method='ffill').fillna(method='bfill')\n",
    "    features = (features - sleep_norms.m)/sleep_norms.s\n",
    "    df_rolled['sleep_states'] = sleep_clfr.predict(features.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(df_rolled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#good\n",
    "my_df = pd.read_csv('../mask9_2018/20180101/AC000W000423061.csv.gz', names=col_names) #good data\n",
    "my_df = my_df.copy().sort_values('timestamp').reset_index()\n",
    "df = my_df.copy()\n",
    "#clean data\n",
    "df.index = pd.to_datetime(df.timestamp, utc=True, unit='s')\n",
    "df = df[(df.base_state>=4) & (df.ble_rssi !=0) & (df.heart_rate_raw >0)]\n",
    "df_valid = df[(df.notification_mask == 0) & (df.heart_rate_raw > 0)]\n",
    "df_valid.plot(x=['timestamp','timestamp'], y=['heart_rate_raw', 'movement_raw'], kind='scatter')\n",
    "plt.show()\n",
    "df.plot(x=['timestamp','timestamp'], y=['heart_rate_raw', 'movement_raw'], kind='scatter')\n",
    "plt.show()\n",
    "my_df.plot(x=['timestamp','timestamp'], y=['heart_rate_raw', 'movement_raw'], kind='scatter')\n",
    "plt.show()\n",
    "print(len(my_df))\n",
    "print(len(df))\n",
    "print(len(df_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bad\n",
    "# my_df = pd.read_csv('../mask9_2018/20181120/AC000W001055137.csv.gz', names=col_names) #bad data\n",
    "my_df = pd.read_csv('../mask9_2018/20180101/AC000W001144880.csv.gz', names=col_names) #bad data\n",
    "\n",
    "my_df = my_df.copy().sort_values('timestamp').reset_index()\n",
    "df = my_df.copy()\n",
    "#clean data\n",
    "df.index = pd.to_datetime(df.timestamp, utc=True, unit='s')\n",
    "df = df[(df.base_state>=4) & (df.ble_rssi !=0) & (df.heart_rate_raw >0)]\n",
    "df_valid = df[(df.notification_mask == 0) & (df.heart_rate_raw > 0)]\n",
    "df_valid.plot(x=['timestamp','timestamp'], y=['heart_rate_raw', 'movement_raw'], kind='scatter')\n",
    "plt.show()\n",
    "df.plot(x=['timestamp','timestamp'], y=['heart_rate_raw', 'movement_raw'], kind='scatter')\n",
    "plt.show()\n",
    "my_df.plot(x=['timestamp','timestamp'], y=['heart_rate_raw', 'movement_raw'], kind='scatter')\n",
    "plt.show()\n",
    "print(len(my_df))\n",
    "print(len(df))\n",
    "print(len(df_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.sort_values('timestamp').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rolled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rolled.loc['2018-11-20 23:50:00+00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data_folder = '../mask9_2018/'\n",
    "all_dirs = os.listdir(log_data_folder)\n",
    "all_dirs.sort()\n",
    "print(all_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data_folder = '../mask9_2018/'\n",
    "all_dirs = os.listdir(log_data_folder)\n",
    "all_dirs.sort()\n",
    "count = 0\n",
    "for d in all_dirs:\n",
    "    count += 1\n",
    "    print(d)\n",
    "    all_files = os.listdir(log_data_folder+d)\n",
    "    for f in all_files:\n",
    "        tic = timeit.default_timer()\n",
    "        p = log_data_folder + d + '/' + f\n",
    "        df = pd.read_csv(p, names=col_names)\n",
    "        df_rolled = roll_up_ten(df)\n",
    "        if(len(df_rolled) > 0):\n",
    "            dp = '../mask9_2018_rolled2/' + df_rolled['dsn'][0] +'.csv.gz'\n",
    "            df_rolled.to_csv(dp, mode='a', header=False, compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
